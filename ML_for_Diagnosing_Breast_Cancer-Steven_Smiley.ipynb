{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     Using Machine Learning to Diagnose Breast Cancer in Python\n",
    "## by:  Steven Smiley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "Find a Machine Learning (ML) model that accurately predicts breast cancer based on the 30 features described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Background:\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "* a) radius (mean of distances from center to points on the perimeter) \n",
    "* b) texture (standard deviation of gray-scale values) \n",
    "* c) perimeter \n",
    "* d) area \n",
    "* e) smoothness (local variation in radius lengths) \n",
    "* f) compactness (perimeter^2 / area - 1.0) \n",
    "* g) concavity (severity of concave portions of the contour) \n",
    "* h) concave points (number of concave portions of the contour) \n",
    "* i) symmetry \n",
    "* j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Abstract:\n",
    "\n",
    "  When it comes to diagnosing breast cancer, we want to make sure we don't have too many false-positives (you don't have cancer, but told you do and go on treatment) or false-negatives (you have cancer, but told you don't and don't get treatment). Therefore, the highest overall accuracy model is chosen.  \n",
    "  \n",
    "  The Data was split into 80% training (~455 people) and 20% testing (~114 people).\n",
    "  \n",
    "  Several different models were evaluated through k-fold Cross-Validation with GridSearchCV, which iterates on different algorithm's hyperparameters:\n",
    "  * Logistic Regression \n",
    "  * Support Vector Machine\n",
    "  * Neural Network\n",
    "  * Random Forest\n",
    "  * Gradient Boost\n",
    "  * eXtreme Gradient Boost\n",
    "\n",
    "\n",
    " All of the models performed well after fine tunning their hyperparameters, but the best model is the one the highest overall accuracy.  Out of the 20% of data witheld in this test (114 random individuals), only a handful were misdiagnosed.  No model is perfect, but I am happy about how accurate my model is here.  If on average less than a handful of people out of 114 are misdiagnosed, that is a good start for making a model.  Furthermore, the Feature Importance plots show that the \"concave points worst\" and \"concave points mean\" were the significant features.  Therefore, I recommend the concave point features should be extracted from each future biopsy as a strong predictor for diagnosing breast cancer.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os # Get Current Directory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pandas as pd # data processing, CSV file I/O (e.i. pd.read_csv)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import subprocess\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hide Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Current Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stevensmiley/Documents/GitHub/BreastCancer\n"
     ]
    }
   ],
   "source": [
    "currentDirectory=os.getcwd()\n",
    "print(currentDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Directorys for Output Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_path(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "        return(path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)\n",
    "        return(path)\n",
    "    return(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory /Users/stevensmiley/Documents/GitHub/BreastCancer/Outputs failed\n",
      "Creation of the directory /Users/stevensmiley/Documents/GitHub/BreastCancer/Outputs/Models failed\n",
      "Creation of the directory /Users/stevensmiley/Documents/GitHub/BreastCancer/Outputs/Figures failed\n"
     ]
    }
   ],
   "source": [
    "# OUTPUTS: Folder for storing OUTPUTS\n",
    "OUTPUT_path=folder_path(currentDirectory+'/Outputs')\n",
    "\n",
    "# Models: Folder for storing models\n",
    "models_path=folder_path(OUTPUT_path+'/Models')\n",
    "# Figures: Folder for storing figures\n",
    "figures_path=folder_path(OUTPUT_path+'/Figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Import and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file not found at location: /kaggle/input/breast-cancer-wisconsin-data/data.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7c83f2731337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Successfully loaded Input file from:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# view the first 10 columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data= pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\n",
    "except OSError:\n",
    "    print (\"Input file not found at location:\",'/kaggle/input/breast-cancer-wisconsin-data/data.csv')\n",
    "    data_path=os.path.join(currentDirectory,'data.csv')\n",
    "    data= pd.read_csv(data_path)\n",
    "    print (\"Successfully loaded Input file from:\",data_path)\n",
    "else:\n",
    "    print ()\n",
    "\n",
    "\n",
    "data.head(10) # view the first 10 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Import and View Data:  Check for Missing Values\n",
    "\n",
    "As the background stated, no missing values should be present.  The following verifies that.  The last column doesn't hold any information and should be removed.  In addition, the diagnosis should be changed to a binary classification of 0= benign and 1=malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Unnamed: 32 variable that has NaN values.\n",
    "data.drop(['Unnamed: 32'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Diagnosis for Cancer from Categorical Variable to Binary\n",
    "diagnosis_num={'B':0,'M':1}\n",
    "data['diagnosis']=data['diagnosis'].map(diagnosis_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Data Changes, look at first 5 rows \n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2  Heatmap with Pearson Correlation Coefficient  for Features\n",
    "A strong correlation is indicated by a Pearson Correlation Coefficient value near 1.  Therefore, when looking at the Heatmap, we want to see what correlates most with the first column, \"diagnosis.\"  It appears that the features of \"concave points worst\" [0.79] has the strongest correlation with \"diagnosis\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix,ax = plt.subplots(figsize=(25,25))\n",
    "fix,ax = plt.subplots(figsize=(22,22))\n",
    "heatmap_data = data.drop(['id'],axis=1)\n",
    "sns.heatmap(heatmap_data.corr(),vmax=1,linewidths=0.01,square=True,annot=True,linecolor=\"white\")\n",
    "bottom,top=ax.get_ylim()\n",
    "ax.set_ylim(bottom+0.5,top-0.5)\n",
    "heatmap_title='Figure 1:  Heatmap with Pearson Correlation Coefficient for Features'\n",
    "ax.set_title(heatmap_title)\n",
    "heatmap_fig=os.path.join(figures_path,'Figure1.Heatmap.png')\n",
    "plt.savefig(heatmap_fig,dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Split Data for Training  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Split Data for Training : Standardize and Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['id','diagnosis'], axis= 1)\n",
    "y = data.diagnosis\n",
    "\n",
    "#Standardize Data\n",
    "scaler = StandardScaler()\n",
    "X=StandardScaler().fit_transform(X.values)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns=(data.drop(['id','diagnosis'], axis= 1)).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb is to hold out 20 percent of the data for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n",
    "\n",
    "\n",
    "#Standardize Data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#Apply transform to both the training and test set\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Split Data for Training: Feature Extraction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Extraction:  Principal Component Analysis: PC1, PC2\n",
    "pca = PCA(n_components=2, random_state=42) \n",
    "# Only fit to the training set\n",
    "pca.fit((X_train))\n",
    "# transform with PCA model from training\n",
    "principalComponents_train = pca.transform(X_train)\n",
    "principalComponents_test = pca.transform(X_test)\n",
    "\n",
    "# Use Pandas DataFrame\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test=pd.DataFrame(X_test)\n",
    "X_train.columns=(data.drop(['id','diagnosis'], axis= 1)).columns\n",
    "X_test.columns=(data.drop(['id','diagnosis'], axis= 1)).columns\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test=pd.DataFrame(y_test)\n",
    "\n",
    "X_train['PC1']=principalComponents_train[:,0]\n",
    "X_train['PC2']=principalComponents_train[:,1]\n",
    "X_test['PC1']=principalComponents_test[:,0]\n",
    "X_test['PC2']=principalComponents_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features=X_train\n",
    "tr_labels=y_train\n",
    "\n",
    "val_features = X_test\n",
    "val_labels=y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Split Data for Training:  Verify the Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the data was split correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train - length:',len(X_train), 'y_train - length:',len(y_train))\n",
    "print('X_test - length:',len(X_test),'y_test - length:',len(y_test))\n",
    "print('Percent heldout for testing:', round(100*(len(X_test)/len(data)),0),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Machine Learning:\n",
    "\n",
    "In order to find a good model, several algorithms are tested on the training dataset. A senstivity study using different Hyperparameters of the algorithms are iterated on with GridSearchCV in order optimize each model. The best model is the one that has the highest accuracy without overfitting by looking at both the training data and the validation data results. Computer time does not appear to be an issue for these models, so it has little weight on deciding between models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch CV\n",
    "\n",
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)[source]¶\n",
    "\n",
    "Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    "Important members are fit, predict.\n",
    "\n",
    "GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.\n",
    "\n",
    "The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: print_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results,name,filename_pr):\n",
    "    with open(filename_pr, mode='w') as file_object:\n",
    "        print(name,file=file_object)\n",
    "        print(name)\n",
    "        print('BEST PARAMS: {}\\n'.format(results.best_params_),file=file_object)\n",
    "        print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "        means = results.cv_results_['mean_test_score']\n",
    "        stds = results.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "            print('{} {} (+/-{}) for {}'.format(name,round(mean, 3), round(std * 2, 3), params),file=file_object)\n",
    "            print('{} {} (+/-{}) for {}'.format(name,round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Machine Learning Models:  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:  Hyperparameter used in GridSearchCV\n",
    "### HP1, C:  float, optional (default=1.0)\n",
    "Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "##### Details\n",
    "Regularization is when a penality is applied with increasing value to prevent overfitting.  The inverse of regularization strength means as the value of C goes up, the value of the regularization strength goes down and vice versa.  \n",
    "##### Values chosen\n",
    "'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Directory\n",
    "path=folder_path(OUTPUT_path+'/Models/LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model_dir=os.path.join(path,'LR_model.pkl')\n",
    "if os.path.exists(LR_model_dir) == False:\n",
    "    lr = LogisticRegression()\n",
    "    parameters = {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "            }\n",
    "    cv=GridSearchCV(lr, parameters, cv=5)\n",
    "    cv.fit(tr_features,tr_labels.values.ravel())      \n",
    "    print_results(cv,'Logistic Regression (LR)',os.path.join(path,'LR_GridSearchCV_results.txt'))\n",
    "    cv.best_estimator_\n",
    "    joblib.dump(cv.best_estimator_,LR_model_dir)\n",
    "else:\n",
    "    print('Already have LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Machine Learning Models:  Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine:  \n",
    "### Hyperparameter used in GridSearchCV\n",
    "#### HP1,  kernelstring, optional (default=’rbf’)\n",
    "Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape (n_samples, n_samples).\n",
    "###### Details\n",
    "A linear kernel type is good when the data is Linearly seperable, which means it can be separated by a single Line.\n",
    "A radial basis function (rbf) kernel type is an expontential function of the squared Euclidean distance between two vectors and a constant.  Since the value of RBF kernel decreases with distance and ranges between zero and one, it has a ready interpretation as a similiarity measure.  \n",
    "###### Values chosen\n",
    "'kernel': ['linear','rbf']\n",
    "\n",
    "#### HP2,  C:  float, optional (default=1.0)\n",
    "Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "###### Details\n",
    "Regularization is when a penality is applied with increasing value to prevent overfitting.  The inverse of regularization strength means as the value of C goes up, the value of the regularization strength goes down and vice versa.  \n",
    "###### Values chosen\n",
    "'C': [0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Directory\n",
    "path=folder_path(OUTPUT_path+'/Models/SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_model_dir=os.path.join(path,'SVM_model.pkl')\n",
    "if os.path.exists(SVM_model_dir) == False:\n",
    "    svc = SVC()\n",
    "    parameters = {\n",
    "            'kernel': ['linear','rbf'],\n",
    "            'C': [0.1, 1, 10]\n",
    "            }\n",
    "    cv=GridSearchCV(svc,parameters, cv=5)\n",
    "    cv.fit(tr_features, tr_labels.values.ravel())\n",
    "    print_results(cv,'Support Vector Machine (SVM)',os.path.join(path,'SVM_GridSearchCV_results.txt'))\n",
    "    cv.best_estimator_\n",
    "    joblib.dump(cv.best_estimator_,SVM_model_dir)\n",
    "else:\n",
    "    print('Already have SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Machine Learning Models:  Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network:  (sklearn)\n",
    "### Hyperparameter used in GridSearchCV\n",
    "#### HP1, hidden_layer_sizes:  tuple, length = n_layers - 2, default (100,)\n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "###### Details\n",
    "A rule of thumb is (2/3)*(# of input features) = neurons per hidden layer. \n",
    "###### Values chosen\n",
    "'hidden_layer_sizes': [(10,),(50,),(100,)]\n",
    "\n",
    "#### HP2, activation:  {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default ‘relu’\n",
    "Activation function for the hidden layer.\n",
    "###### Details\n",
    "* ‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "* ‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "* ‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "* ‘relu’, the rectified linear unit function, returns f(x) = max(0, x)   \n",
    "###### Values chosen\n",
    "'hidden_layer_sizes': [(10,),(50,),(100,)]\n",
    "\n",
    "#### HP3, learning_rate:  {‘constant’, ‘invscaling’, ‘adaptive’}, default ‘constant’\n",
    "Learning rate schedule for weight updates.\n",
    "###### Details\n",
    "* ‘constant’ is a constant learning rate given by ‘learning_rate_init’.\n",
    "* ‘invscaling’ gradually decreases the learning rate at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "* ‘adaptive’ keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if ‘early_stopping’ is on, the current learning rate is divided by 5.\n",
    "\n",
    "Only used when solver='sgd'.\n",
    "  \n",
    "###### Values chosen\n",
    "'learning_rate': ['constant','invscaling','adaptive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MLPClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Directory\n",
    "path=folder_path(OUTPUT_path+'/Models/MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model_dir=os.path.join(path,'MLP_model.pkl')\n",
    "if os.path.exists(MLP_model_dir) == False:\n",
    "    mlp = MLPClassifier()\n",
    "    parameters = {\n",
    "            'hidden_layer_sizes': [(10,),(50,),(100,)],\n",
    "            'activation': ['relu','tanh','logistic'],\n",
    "            'learning_rate': ['constant','invscaling','adaptive']\n",
    "            }\n",
    "    cv=GridSearchCV(mlp, parameters, cv=5)\n",
    "    cv.fit(tr_features, tr_labels.values.ravel())\n",
    "    print_results(cv,'Neural Network (MLP)',os.path.join(path,'MLP_GridSearchCV_results.txt'))\n",
    "    cv.best_estimator_\n",
    "    joblib.dump(cv.best_estimator_,MLP_model_dir)\n",
    "else:\n",
    "    print('Already have MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 Machine Learning Models:  Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest:  \n",
    "### Hyperparameter used in GridSearchCV\n",
    "#### HP1, n_estimators:  integer, optional (default=100)\n",
    "The number of trees in the forest.\n",
    "\n",
    "Changed in version 0.22: The default value of n_estimators changed from 10 to 100 in 0.22.\n",
    "###### Details\n",
    "Usually 500 does the trick and the accuracy and out of bag error doesn't change much after. \n",
    "###### Values chosen\n",
    "'n_estimators': [500],\n",
    "\n",
    "#### HP2, max_depth:  integer or None, optional (default=None)\n",
    "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "###### Details\n",
    "None usually does the trick, but a few shallow trees are tested. \n",
    "###### Values chosen\n",
    "'max_depth': [5,7,9, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Directory\n",
    "path=folder_path(OUTPUT_path+'/Models/RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model_dir=os.path.join(path,'RF_model.pkl')\n",
    "if os.path.exists(RF_model_dir) == False:\n",
    "    rf = RandomForestClassifier(oob_score=False)\n",
    "    parameters = {\n",
    "            'n_estimators': [500],\n",
    "            'max_depth': [5,7,9, None]\n",
    "            }\n",
    "    cv = GridSearchCV(rf, parameters, cv=5)\n",
    "    cv.fit(tr_features, tr_labels.values.ravel())\n",
    "    print_results(cv,'Random Forest (RF)',os.path.join(path,'RF_GridSearchCV_results.txt'))\n",
    "    cv.best_estimator_\n",
    "    joblib.dump(cv.best_estimator_,RF_model_dir)\n",
    "else:\n",
    "    print('Already have RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 Machine Learning Models:  Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting:  \n",
    "### Hyperparameter used in GridSearchCV\n",
    "#### HP1, n_estimators:  int (default=100)\n",
    "The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "###### Details\n",
    "Usually 500 does the trick and the accuracy and out of bag error doesn't change much after. \n",
    "###### Values chosen\n",
    "'n_estimators': [5, 50, 250, 500],\n",
    "\n",
    "#### HP2, max_depth:  integer, optional (default=3)\n",
    "maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
    "###### Details\n",
    "A variety of shallow trees are tested. \n",
    "###### Values chosen\n",
    "'max_depth': [1, 3, 5, 7, 9],\n",
    "\n",
    "#### HP3, learning_rate:  float, optional (default=0.1)\n",
    "learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
    "###### Details\n",
    "A variety was chosen because of the trade-off.\n",
    "###### Values chosen\n",
    "'learning_rate': [0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Directory\n",
    "path=folder_path(OUTPUT_path+'/Models/GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_model_dir=os.path.join(path,'GB_model.pkl')\n",
    "if os.path.exists(GB_model_dir) == False:\n",
    "    gb = GradientBoostingClassifier()\n",
    "    parameters = {\n",
    "            'n_estimators': [5, 50, 250, 500],\n",
    "            'max_depth': [1, 3, 5, 7, 9],\n",
    "            'learning_rate': [0.01, 0.1, 1]\n",
    "            }\n",
    "    cv=GridSearchCV(gb, parameters, cv=5)\n",
    "    cv.fit(tr_features, tr_labels.values.ravel())\n",
    "    print_results(cv,'Gradient Boost (GB)',os.path.join(path,'GR_GridSearchCV_results.txt'))\n",
    "    cv.best_estimator_\n",
    "    joblib.dump(cv.best_estimator_,GB_model_dir)\n",
    "else:\n",
    "    print('Already have GB') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6 Machine Learning Models:  eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eXtreme Gradient Boosting:  \n",
    "### Hyperparameter used in GridSearchCV\n",
    "#### HP1, n_estimators:  (int) – Number of trees to fit.\n",
    "###### Details\n",
    "Usually 500 does the trick and the accuracy and out of bag error doesn't change much after. \n",
    "###### Values chosen\n",
    "'n_estimators': [5, 50, 250, 500],\n",
    "\n",
    "#### HP2, max_depth:  (int) – \n",
    "Maximum tree depth for base learners.\n",
    "###### Details\n",
    "A variety of shallow trees are tested. \n",
    "###### Values chosen\n",
    "'max_depth': [1, 3, 5, 7, 9],\n",
    "\n",
    "#### HP3, learning_rate: (float) – \n",
    "Boosting learning rate (xgb’s “eta”)\n",
    "###### Details\n",
    "A variety was chosen because of the trade-off.\n",
    "###### Values chosen\n",
    "'learning_rate': [0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Directory\n",
    "path=folder_path(OUTPUT_path+'/Models/XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model_dir=os.path.join(path,'XGB_model.pkl')\n",
    "if os.path.exists(XGB_model_dir) == False:\n",
    "    xgb = XGBClassifier()\n",
    "    parameters = {\n",
    "            'n_estimators': [5, 50, 250, 500],\n",
    "            'max_depth': [1, 3, 5, 7, 9],\n",
    "            'learning_rate': [0.01, 0.1, 1]\n",
    "            }\n",
    "    cv=GridSearchCV(xgb, parameters, cv=5)\n",
    "    cv.fit(tr_features, tr_labels.values.ravel())\n",
    "    print_results(cv,'eXtreme Gradient Boost (XGB)',os.path.join(path,'XGB_GridSearchCV_results.txt'))\n",
    "    cv.best_estimator_\n",
    "    joblib.dump(cv.best_estimator_,XGB_model_dir)\n",
    "else:\n",
    "    print('Already have XGB')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all models\n",
    "models = {}\n",
    "\n",
    "#for mdl in ['LR', 'SVM', 'MLP', 'RF', 'GB','XGB']:\n",
    "for mdl in ['LR', 'SVM', 'MLP', 'RF', 'GB','XGB']:\n",
    "    model_path=os.path.join(OUTPUT_path,'Models/{}/{}_model.pkl')\n",
    "    models[mdl] = joblib.load(model_path.format(mdl,mdl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(fig_path,name, model, features, labels, y_test_ev, fc):\n",
    "        CM_fig=os.path.join(fig_path,'Figure{}.A_{}_Confusion_Matrix.png'.format(fc,name))\n",
    "        VI_fig=os.path.join(fig_path,'Figure{}.B_{}_Variable_Importance_Plot.png'.format(fc,name))\n",
    "        \n",
    "        start = time()\n",
    "        pred = model.predict(features)\n",
    "        end = time()\n",
    "        y_truth=y_test_ev\n",
    "        accuracy = round(accuracy_score(labels, pred), 3)\n",
    "        precision = round(precision_score(labels, pred), 3)\n",
    "        recall = round(recall_score(labels, pred), 3)\n",
    "        print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,\n",
    "                                                                                       accuracy,\n",
    "                                                                                       precision,\n",
    "                                                                                       recall,\n",
    "                                                                                       round((end - start)*1000, 1)))\n",
    "        \n",
    "        \n",
    "        pred=pd.DataFrame(pred)\n",
    "        pred.columns=['diagnosis']\n",
    "        # Convert Diagnosis for Cancer from Binary to Categorical\n",
    "        diagnosis_name={0:'Benign',1:'Malginant'}\n",
    "        y_truth['diagnosis']=y_truth['diagnosis'].map(diagnosis_name)\n",
    "        pred['diagnosis']=pred['diagnosis'].map(diagnosis_name)\n",
    "        class_names = ['Benign','Malginant']        \n",
    "        cm = confusion_matrix(y_test_ev, pred, class_names)\n",
    "        \n",
    "        FP_L='False Positive'\n",
    "        FP = cm[0][1]\n",
    "        FN_L='False Negative'\n",
    "        FN = cm[1][0]\n",
    "        TP_L='True Positive'\n",
    "        TP = cm[1][1]\n",
    "        TN_L='True Negative'\n",
    "        TN = cm[0][0]\n",
    "\n",
    "        #TPR_L= 'Sensitivity, hit rate, recall, or true positive rate'\n",
    "        TPR_L= 'Sensitivity'\n",
    "        TPR = round(TP/(TP+FN),3)\n",
    "        #TNR_L= 'Specificity or true negative rate'\n",
    "        TNR_L= 'Specificity'\n",
    "        TNR = round(TN/(TN+FP),3) \n",
    "        #PPV_L= 'Precision or positive predictive value'\n",
    "        PPV_L= 'Precision'\n",
    "        PPV = round(TP/(TP+FP),3)\n",
    "        #NPV_L= 'Negative predictive value'\n",
    "        NPV_L= 'NPV'\n",
    "        NPV = round(TN/(TN+FN),3)\n",
    "        #FPR_L= 'Fall out or false positive rate'\n",
    "        FPR_L= 'FPR'\n",
    "        FPR = round(FP/(FP+TN),3)\n",
    "        #FNR_L= 'False negative rate'\n",
    "        FNR_L= 'FNR'\n",
    "        FNR = round(FN/(TP+FN),3)\n",
    "        #FDR_L= 'False discovery rate'\n",
    "        FDR_L= 'FDR'\n",
    "        FDR = round(FP/(TP+FP),3)\n",
    "\n",
    "        ACC_L= 'Accuracy'\n",
    "        ACC = round((TP+TN)/(TP+FP+FN+TN),3)\n",
    "        \n",
    "        stats_data = {'Name':name,\n",
    "                     ACC_L:ACC,\n",
    "                     FP_L:FP,\n",
    "                     FN_L:FN,\n",
    "                     TP_L:TP,\n",
    "                     TN_L:TN,\n",
    "                     TPR_L:TPR,\n",
    "                     TNR_L:TNR,\n",
    "                     PPV_L:PPV,\n",
    "                     NPV_L:NPV,\n",
    "                     FPR_L:FPR,\n",
    "                     FNR_L:FDR}\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(cm,cmap=plt.cm.gray_r)\n",
    "        plt.title('Figure {}.A: {} Confusion Matrix on Unseen Test Data'.format(fc,name),y=1.08)\n",
    "        fig.colorbar(cax)\n",
    "        ax.set_xticklabels([''] + class_names)\n",
    "        ax.set_yticklabels([''] + class_names)\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        for i in range(len(class_names)):\n",
    "            for j in range(len(class_names)):\n",
    "                text = ax.text(j, i, cm[i, j],\n",
    "                               ha=\"center\", va=\"center\", color=\"r\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(CM_fig,dpi=400,bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        \n",
    "        if  name == 'RF' or name == 'GB' or name == 'XGB': \n",
    "            # Get numerical feature importances\n",
    "            importances = list(model.feature_importances_)\n",
    "            importances=100*(importances/max(importances))               \n",
    "            feature_list = list(features.columns)\n",
    "            sorted_ID=np.argsort(importances)   \n",
    "            plt.figure(figsize=[10,10])\n",
    "            plt.barh(sort_list(feature_list,importances),importances[sorted_ID],align='center')\n",
    "            plt.title('Figure {}.B: {} Variable Importance Plot'.format(fc,name))\n",
    "            plt.xlabel('Relative Importance')\n",
    "            plt.ylabel('Feature') \n",
    "            plt.savefig(VI_fig,dpi=300,bbox_inches='tight')\n",
    "            #plt.show()\n",
    "        \n",
    "        return accuracy,name, model, stats_data\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function:  sort_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def sort_list(list1, list2): \n",
    "        zipped_pairs = zip(list2, list1)   \n",
    "        z = [x for _, x in sorted(zipped_pairs)]       \n",
    "        return z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for best model using test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ev_accuracy=[None]*len(models)\n",
    "ev_name=[None]*len(models)\n",
    "ev_model=[None]*len(models)\n",
    "ev_stats=[None]*len(models)\n",
    "count=1\n",
    "for name, mdl in models.items():\n",
    "        y_test_ev=y_test\n",
    "        ev_accuracy[count-1],ev_name[count-1],ev_model[count-1], ev_stats[count-1] = evaluate_model(figures_path,\n",
    "                                                                                                    name,\n",
    "                                                                                                    mdl,\n",
    "                                                                                                    val_features,\n",
    "                                                                                                    val_labels,\n",
    "                                                                                                    y_test_ev,\n",
    "                                                                                                    count+1)\n",
    "        diagnosis_name={'Benign':0,'Malginant':1}\n",
    "        y_test['diagnosis']=y_test['diagnosis'].map(diagnosis_name)\n",
    "        count=count+1\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name=ev_name[ev_accuracy.index(max(ev_accuracy))]    #picks the maximum accuracy\n",
    "print('Best Model:',best_name,'with Accuracy of ',max(ev_accuracy))   \n",
    "best_model=ev_model[ev_accuracy.index(max(ev_accuracy))]    #picks the maximum accuracy\n",
    "\n",
    "if best_name == 'RF' or best_name == 'GB' or best_name == 'XGB': \n",
    "    # Get numerical feature importances\n",
    "    importances = list(best_model.feature_importances_)\n",
    "    importances=100*(importances/max(importances))               \n",
    "    feature_list = list(X.columns)\n",
    "    sorted_ID=np.argsort(importances)   \n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.barh(sort_list(feature_list,importances),importances[sorted_ID],align='center')\n",
    "    plt.title('Figure 8:  Variable Importance Plot -- {}'.format(best_name))\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.ylabel('Feature') \n",
    "    plt.savefig(os.path.join(figures_path,'Figure8.png'),dpi=300,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 8. Conclusions \n",
    "  When it comes to diagnosing breast cancer, we want to make sure we don't have too many false-positives (you don't have cancer, but told you do and go on treatment) or false-negatives (you have cancer, but told you don't and don't get treatment). Therefore, the highest overall accuracy model is chosen.  \n",
    "\n",
    "  All of the models performed well after fine tunning their hyperparameters, but the best model is the one the highest overall accuracy.  Out of the 20% of data witheld in this test (114 random individuals), only a handful were misdiagnosed.  No model is perfect, but I am happy about how accurate my model is here.  If on average less than a handful of people out of 114 are misdiagnosed, that is a good start for making a model.  Furthermore, the Feature Importance plots show that the \"concave points worst\" and \"concave points mean\" were the significant features.  Therefore, I recommend the concave point features should be extracted from each future biopsy as a strong predictor for diagnosing breast cancer.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_stats=pd.DataFrame(ev_stats)\n",
    "print(ev_stats.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
